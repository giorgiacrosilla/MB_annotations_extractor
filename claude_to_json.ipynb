{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Produce a JSON first, and then fill the trig template.\n",
    "First cell is a test, the rest is what i actually used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k89CwtBJWxd5",
    "outputId": "1c6799c9-d1e1-44bc-83df-c1eececc1a1b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved extracted_places/1p_place_1_villa rosa, fiesole.json\n",
      "Saved extracted_places/1p_place_2_academy.json\n",
      "Saved extracted_places/1p_place_3_florence.json\n",
      "Saved extracted_places/1p_place_4_uffizi.json\n",
      "Complete response:\n",
      "{\n",
      "    \"places\": [\n",
      "        {\n",
      "            \"name\": \"Villa Rosa, Fiesole\",\n",
      "            \"coordinates\": \"(43.8080, 11.2926)\",\n",
      "            \"wiki_id\": \"Q3746\",\n",
      "            \"start_position\": 29,\n",
      "            \"end_position\": 48,\n",
      "            \"line\": \"/p[1]\",\n",
      "            \"uuid\": \"f47ac10b-58cc-4372-a567-0e02b2c3d479\"\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"Academy\",\n",
      "            \"coordinates\": \"(43.7766, 11.2588)\",\n",
      "            \"wiki_id\": \"Q1756942\",\n",
      "            \"start_position\": 165,\n",
      "            \"end_position\": 172,\n",
      "            \"line\": \"/p[2]\",\n",
      "            \"uuid\": \"550e8400-e29b-41d4-a716-446655440000\"\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"Florence\",\n",
      "            \"coordinates\": \"(43.7696, 11.2558)\",\n",
      "            \"wiki_id\": \"Q2044\",\n",
      "            \"start_position\": 321,\n",
      "            \"end_position\": 329,\n",
      "            \"line\": \"/p[4]\",\n",
      "            \"uuid\": \"6ba7b810-9dad-11d1-80b4-00c04fd430c8\"\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"Uffizi\",\n",
      "            \"coordinates\": \"(43.7677, 11.2553)\",\n",
      "            \"wiki_id\": \"Q127665\",\n",
      "            \"start_position\": 418,\n",
      "            \"end_position\": 424,\n",
      "            \"line\": \"/p[4]\",\n",
      "            \"uuid\": \"7c9e6679-7425-40de-944b-e07fc1f90ae7\"\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import base64\n",
    "import json\n",
    "import pandas as pd\n",
    "import anthropic\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "def process_text_pair(client, front_text):\n",
    "    \"\"\"Process a pair of text inputs (front and back) and generate JSON output\"\"\"\n",
    "    try:\n",
    "        system_prompt = \"\"\"\n",
    "you're an ai assistant specialized in extracting places from texts as JSON files. JSON that you produce must follow this format:\n",
    "{\n",
    "  name: name of the place\n",
    "  coordinates: coordinates of the place in the format (40,04, 30.55)\n",
    "  wiki_id:wikidata id of the place\n",
    "  start_position: starting position of the place in the text\n",
    "  end_position: ending position of the place in the text\n",
    "  line: line of the text where the place is mentioned formatted in this way /p[1] where 1 is the line number. Line is different from paragraph\n",
    "  uuid: a VALID UUID identifier.\n",
    "}\n",
    "        \"\"\"\n",
    "\n",
    "        initial_prompt = \"\"\"\n",
    "extract only the visited places from text. response must be in JSON. Create a different JSON for different places extracted, where you must add a field for the name of the places and one for the coordinates\n",
    "        \"\"\"\n",
    "\n",
    "        response = client.messages.create(\n",
    "            model=\"claude-3-5-sonnet-20240620\",\n",
    "            max_tokens=2048,\n",
    "            system=system_prompt,\n",
    "            temperature=0,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\"type\": \"text\", \"text\": initial_prompt},\n",
    "                        {\"type\": \"text\", \"text\": front_text}\n",
    "                    ]\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": \"Here is the JSON requested:\\n{\"\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        transcription_text = response.content[0].text\n",
    "        if not transcription_text.strip().startswith('{'):\n",
    "            transcription_text = '{' + transcription_text.strip()\n",
    "\n",
    "        # Parse the text as JSON to validate it\n",
    "        try:\n",
    "            transcription = json.loads(transcription_text)\n",
    "\n",
    "            # Create output directory if it doesn't exist\n",
    "            output_dir = \"extracted_places\"\n",
    "            if not os.path.exists(output_dir):\n",
    "                os.makedirs(output_dir)\n",
    "\n",
    "            # Save each place as a separate JSON file\n",
    "            if \"places\" in transcription:\n",
    "                for i, place in enumerate(transcription[\"places\"]):\n",
    "                    filename = f\"{output_dir}/1p_place_{i+1}_{place['name'].lower()}.json\"\n",
    "                    with open(filename, 'w', encoding='utf-8') as f:\n",
    "                        json.dump(place, f, indent=4)\n",
    "                    print(f\"Saved {filename}\")\n",
    "\n",
    "            return transcription\n",
    "\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error parsing JSON: {str(e)}\")\n",
    "            return {\"error\": \"Invalid JSON format\", \"raw_text\": transcription_text}\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing text: {str(e)}\")\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        # Initialize Claude client\n",
    "        client = anthropic.Anthropic(\n",
    "            api_key=''\n",
    "        )\n",
    "\n",
    "        # Example usage\n",
    "        front_text = \"\"\"Friday, October 25, 1895, Villa Rosa, Fiesole\n",
    "A day with little to record, as we worked over the proofs of the Florentine Painters. We went down to the Academy\n",
    "in the afternoon, and spent an hour in the Library, reading the Giornali.\n",
    "We discovered Michelangelo’s S. Matteo!!!\n",
    "Saturday, October 26, 1895\n",
    "Again the damned Proofs - and a run into Florence to get the number of a Pollaiuolo. We meet Miss Hertz and a\n",
    "        friend of hers in the Uffizi. Miss Hertz made us think of nothing but Bouvard, except possibly Aunty Lill!\n",
    "        Bernhard then called on La baronne Puliga (“Brada”) and on Benn, while I walked home and devoted myself to some\n",
    "        deadly dull writing on the French provincial galleries\n",
    "All the evening we corrected, and corrected, and corrected proofs - until nearly 11, when we read Bernhard’s\n",
    "        article on the Italians in New York and Boston\n",
    "\"\"\"\n",
    "\n",
    "        transcription = process_text_pair(client, front_text)\n",
    "        print(\"Complete response:\")\n",
    "        print(json.dumps(transcription, indent=4))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in main: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zUQxWKNGHMXS",
    "outputId": "d924c8d2-5f39-4f99-c8e9-296376a0cd74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No places extracted from 100.txt\n",
      "No places extracted from 101.txt\n",
      "Processed and saved rdf_output/102_place_1_lake garda.trig\n",
      "Processed and saved rdf_output/103_place_1_ratisbon.trig\n",
      "Processed and saved rdf_output/103_place_2_schottenkirche.trig\n",
      "Processed and saved rdf_output/103_place_3_cathedral of regensburg.trig\n",
      "Processed and saved rdf_output/104_place_1_regensburg.trig\n",
      "Processed and saved rdf_output/104_place_2_walhalla.trig\n",
      "No places extracted from 105.txt\n",
      "Processed and saved rdf_output/106_place_1_munich.trig\n",
      "Processed and saved rdf_output/107_place_1_regensburg.trig\n",
      "Processed and saved rdf_output/107_place_2_munich.trig\n",
      "Processed and saved rdf_output/107_place_3_pinacothek.trig\n",
      "Processed and saved rdf_output/107_place_4_glaspalast.trig\n",
      "Processed and saved rdf_output/108_place_1_propylaia.trig\n",
      "Processed and saved rdf_output/108_place_2_glyptothek.trig\n",
      "Processed and saved rdf_output/109_place_1_munich.trig\n",
      "Processed and saved rdf_output/110_place_1_munich.trig\n",
      "Processed and saved rdf_output/110_place_2_augsburg.trig\n",
      "Processed and saved rdf_output/111_place_1_munich.trig\n",
      "Processed and saved rdf_output/111_place_2_pinacothek.trig\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 222\u001b[0m\n\u001b[0;32m    219\u001b[0m     processor\u001b[38;5;241m.\u001b[39mprocess_batch(input_directory)\n\u001b[0;32m    221\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 222\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[6], line 219\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    216\u001b[0m input_directory \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./1891/1891/txt\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Change this to your input directory path\u001b[39;00m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;66;03m# Process all text files in the directory\u001b[39;00m\n\u001b[1;32m--> 219\u001b[0m \u001b[43mprocessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_directory\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[6], line 186\u001b[0m, in \u001b[0;36mTextToRDFProcessor.process_batch\u001b[1;34m(self, input_directory)\u001b[0m\n\u001b[0;32m    183\u001b[0m     text \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m    185\u001b[0m \u001b[38;5;66;03m# Extract places\u001b[39;00m\n\u001b[1;32m--> 186\u001b[0m places_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_places\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m places_data \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m places_data\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplaces\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo places extracted from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[6], line 40\u001b[0m, in \u001b[0;36mTextToRDFProcessor.extract_places\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m     16\u001b[0m system_prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mYou are an AI assistant specialized in extracting places from texts into JSON format.\u001b[39m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;124mYour task is to analyze the text and extract ONLY the places in which Mary Berenson says she was in a particular day, create a JSON object with these exact fields:\u001b[39m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;124m- name: name of the place\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;124m    ]\u001b[39m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;124m}\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 40\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclaude-3-5-sonnet-latest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2048\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[43m        \u001b[49m\u001b[43msystem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msystem_prompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPlease analyze carefully the diary page and extract all the places in which Mary Berenson said SHE WAS IN A PARTICULAR DAY and that could be associated with coordinates. \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mtext\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m     49\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;66;03m# Extract just the JSON part from Claude's response\u001b[39;00m\n\u001b[0;32m     54\u001b[0m     response_text \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mcontent[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtext\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\anthropic\\_utils\\_utils.py:274\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    272\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    273\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 274\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\anthropic\\resources\\messages.py:878\u001b[0m, in \u001b[0;36mMessages.create\u001b[1;34m(self, max_tokens, messages, model, metadata, stop_sequences, stream, system, temperature, tool_choice, tools, top_k, top_p, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    871\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m DEPRECATED_MODELS:\n\u001b[0;32m    872\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    873\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe model \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is deprecated and will reach end-of-life on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mDEPRECATED_MODELS[model]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mPlease migrate to a newer model. Visit https://docs.anthropic.com/en/docs/resources/model-deprecations for more information.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    874\u001b[0m         \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m,\n\u001b[0;32m    875\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[0;32m    876\u001b[0m     )\n\u001b[1;32m--> 878\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/v1/messages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    882\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    883\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    884\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    885\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    886\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop_sequences\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop_sequences\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    887\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    888\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    889\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    890\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    891\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    892\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_k\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    893\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    894\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    895\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessage_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMessageCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    896\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    897\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    898\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m    899\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    900\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMessage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    901\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    902\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mRawMessageStreamEvent\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    903\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\anthropic\\_base_client.py:1260\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1246\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1247\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1248\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1255\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1256\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1257\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1258\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1259\u001b[0m     )\n\u001b[1;32m-> 1260\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\anthropic\\_base_client.py:937\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    928\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[0;32m    929\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    930\u001b[0m     cast_to: Type[ResponseT],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    935\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    936\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m--> 937\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    938\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    939\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    940\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    941\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    942\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    943\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\anthropic\\_base_client.py:973\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    970\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSending HTTP Request: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, request\u001b[38;5;241m.\u001b[39mmethod, request\u001b[38;5;241m.\u001b[39murl)\n\u001b[0;32m    972\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 973\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39msend(\n\u001b[0;32m    974\u001b[0m         request,\n\u001b[0;32m    975\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_stream_response_body(request\u001b[38;5;241m=\u001b[39mrequest),\n\u001b[0;32m    976\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    977\u001b[0m     )\n\u001b[0;32m    978\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    979\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered httpx.TimeoutException\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpx\\_client.py:926\u001b[0m, in \u001b[0;36mClient.send\u001b[1;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[0;32m    922\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_timeout(request)\n\u001b[0;32m    924\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[1;32m--> 926\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    929\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    930\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    931\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    932\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    933\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpx\\_client.py:954\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[1;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[0;32m    951\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[0;32m    953\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 954\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    955\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    956\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    957\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    959\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    960\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpx\\_client.py:991\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[1;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[0;32m    988\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    989\u001b[0m     hook(request)\n\u001b[1;32m--> 991\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    992\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    993\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpx\\_client.py:1027\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1023\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1024\u001b[0m     )\n\u001b[0;32m   1026\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[1;32m-> 1027\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1029\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[0;32m   1031\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpx\\_transports\\default.py:236\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    223\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[0;32m    224\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m    225\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    233\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[0;32m    234\u001b[0m )\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[1;32m--> 236\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[0;32m    241\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[0;32m    242\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m    243\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[0;32m    244\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[0;32m    245\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpcore\\_sync\\connection_pool.py:216\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    213\u001b[0m         closing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_requests_to_connections()\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[1;32m--> 216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, Iterable)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpcore\\_sync\\connection_pool.py:196\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    192\u001b[0m connection \u001b[38;5;241m=\u001b[39m pool_request\u001b[38;5;241m.\u001b[39mwait_for_connection(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[1;32m--> 196\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[0;32m    202\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[0;32m    204\u001b[0m     pool_request\u001b[38;5;241m.\u001b[39mclear_connection()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpcore\\_sync\\connection.py:101\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[1;32m--> 101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpcore\\_sync\\http11.py:143\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[1;32m--> 143\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpcore\\_sync\\http11.py:113\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[0;32m    106\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[0;32m    107\u001b[0m     (\n\u001b[0;32m    108\u001b[0m         http_version,\n\u001b[0;32m    109\u001b[0m         status,\n\u001b[0;32m    110\u001b[0m         reason_phrase,\n\u001b[0;32m    111\u001b[0m         headers,\n\u001b[0;32m    112\u001b[0m         trailing_data,\n\u001b[1;32m--> 113\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_receive_response_headers(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    114\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    115\u001b[0m         http_version,\n\u001b[0;32m    116\u001b[0m         status,\n\u001b[0;32m    117\u001b[0m         reason_phrase,\n\u001b[0;32m    118\u001b[0m         headers,\n\u001b[0;32m    119\u001b[0m     )\n\u001b[0;32m    121\u001b[0m network_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpcore\\_sync\\http11.py:186\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    183\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 186\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[0;32m    188\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpcore\\_sync\\http11.py:224\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    221\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[1;32m--> 224\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m    226\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    230\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    234\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[0;32m    236\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpcore\\_backends\\sync.py:126\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[1;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[1;32m--> 126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\ssl.py:1259\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[1;34m(self, buflen, flags)\u001b[0m\n\u001b[0;32m   1255\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1256\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1257\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1258\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1259\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1260\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1261\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\ssl.py:1132\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1130\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[0;32m   1131\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1132\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1133\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[0;32m   1134\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import uuid\n",
    "import anthropic\n",
    "from datetime import datetime\n",
    "\n",
    "class TextToRDFProcessor:\n",
    "    def __init__(self, api_key):\n",
    "        self.client = anthropic.Anthropic(api_key=api_key)\n",
    "        self.output_dir = \"rdf_output\"\n",
    "        if not os.path.exists(self.output_dir):\n",
    "            os.makedirs(self.output_dir)\n",
    "\n",
    "    def extract_places(self, text):\n",
    "        \"\"\"Extract places from text using Claude API\"\"\"\n",
    "        system_prompt = \"\"\"You are an AI assistant specialized in extracting places from texts into JSON format.\n",
    "        Your task is to analyze the text and extract ONLY the places in which Mary Berenson says she was in a particular day, create a JSON object with these exact fields:\n",
    "        - name: name of the place\n",
    "        - coordinates: coordinates in format (40.04, 30.55)\n",
    "        - wiki_id: the CORRECT wikidata ID\n",
    "        - line: text line reference in format /p[N] where N is line number\n",
    "        - start_position: character position where date mention starts: Offset resets after each line, so first character of the second line will have start_position = 0\n",
    "        - end_position: character position where date mention ends. Offset resets after each line.\n",
    "\n",
    "        Return the results in this exact format, with no additional text:\n",
    "        {\n",
    "            \"places\": [\n",
    "                {\n",
    "                    \"name\": \"place name\",\n",
    "                    \"coordinates\": \"(lat, long)\",\n",
    "                    \"wiki_id\": \"Q12345\",\n",
    "                    \"start_position\": \"23\",\n",
    "                    \"end_position\": \"35\",\n",
    "                    \"line\": \"/p[1]\"\n",
    "                }\n",
    "            ]\n",
    "        }\"\"\"\n",
    "\n",
    "        try:\n",
    "            response = self.client.messages.create(\n",
    "                model=\"claude-3-5-sonnet-latest\",\n",
    "                max_tokens=2048,\n",
    "                system=system_prompt,\n",
    "                temperature=0,\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": f\"Please analyze carefully the diary page and extract all the places in which Mary Berenson said SHE WAS IN A PARTICULAR DAY and that could be associated with coordinates. \\n\\n{text}\"\n",
    "                    }\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            # Extract just the JSON part from Claude's response\n",
    "            response_text = response.content[0].text\n",
    "\n",
    "            # Find the JSON object bounds\n",
    "            start_idx = response_text.find('{')\n",
    "            end_idx = response_text.rfind('}') + 1\n",
    "\n",
    "            if start_idx == -1 or end_idx == 0:\n",
    "                raise ValueError(\"No valid JSON found in response\")\n",
    "\n",
    "            json_str = response_text[start_idx:end_idx]\n",
    "\n",
    "            # Parse the JSON\n",
    "            places_data = json.loads(json_str)\n",
    "\n",
    "            # Validate the structure\n",
    "            if \"places\" not in places_data:\n",
    "                places_data = {\"places\": [places_data]}\n",
    "\n",
    "            return places_data\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting places: {str(e)}\")\n",
    "            print(f\"Raw response: {response_text}\")\n",
    "            return None\n",
    "\n",
    "    def generate_uuids(self):\n",
    "        \"\"\"Generate a set of UUIDs for use in the Trig template\"\"\"\n",
    "        return {\n",
    "            'main': str(uuid.uuid4()),\n",
    "            'uuid2': str(uuid.uuid4()),\n",
    "            'uuid3': str(uuid.uuid4()),\n",
    "            'uuid4': str(uuid.uuid4()),\n",
    "            'uuid5': str(uuid.uuid4()),\n",
    "            'uuid6': str(uuid.uuid4()),\n",
    "            'uuid7': str(uuid.uuid4())\n",
    "        }\n",
    "\n",
    "    def convert_to_trig(self, place_data, input_filename):\n",
    "        \"\"\"Convert a single place data to Trig format\"\"\"\n",
    "        uuids = self.generate_uuids()\n",
    "        creation_date = datetime.now().isoformat()\n",
    "\n",
    "        trig_template = f\"\"\"<https://mbdiaries.itatti.harvard.edu/annotation/{uuids['main']}/container/context> {{\n",
    "      <https://mbdiaries.itatti.harvard.edu/diary/1894-95/document/5/offset-{uuids['uuid7']}>\n",
    "        a oa:TextPositionSelector;\n",
    "        oa:end \"{place_data.get('start_position', '')}\"^^xsd:nonNegativeInteger;\n",
    "        oa:start \"{place_data.get('start_position', '')}\"^^xsd:nonNegativeInteger .\n",
    "\n",
    "      <https://mbdiaries.itatti.harvard.edu/diary/1894-95/document/5/offset-{uuids['uuid3']}>\n",
    "        a oa:TextPositionSelector;\n",
    "        oa:end \"{place_data.get('end_position', '')}\"^^xsd:nonNegativeInteger;\n",
    "        oa:start \"{place_data.get('end_position', '')}\"^^xsd:nonNegativeInteger .\n",
    "\n",
    "      mbdiaries-annotation:{uuids['main']} a oa:Annotation, crmdig:D29_Annotation_Object;\n",
    "        crmdig:L48i_was_annotation_created_by <https://mbdiaries.itatti.harvard.edu/diary/1894-95/document/5/annotation-event-{uuids['uuid2']}>;\n",
    "        oa:hasBody <https://mbdiaries.itatti.harvard.edu/annotation/{uuids['main']}/body>;\n",
    "        oa:hasTarget <https://mbdiaries.itatti.harvard.edu/diary/1894-95/document/5/range-source-{uuids['uuid4']}> .\n",
    "\n",
    "      <https://mbdiaries.itatti.harvard.edu/annotation/{uuids['main']}/container>\n",
    "        a ldp:Resource, prov:Entity;\n",
    "        prov:wasAttributedTo User:agent;\n",
    "        prov:generatedAtTime \"{creation_date}\"^^xsd:dateTime .\n",
    "\n",
    "      <https://mbdiaries.itatti.harvard.edu/diary/1894-95/document/5/range-source-{uuids['uuid4']}>\n",
    "        a oa:SpecificResource;\n",
    "        oa:hasSource <https://mbdiaries.itatti.harvard.edu/diary/1894-95/document/5>;\n",
    "        oa:hasSelector <https://mbdiaries.itatti.harvard.edu/diary/1894-95/document/5/range-{uuids['uuid4']}>;\n",
    "        rdf:value \"{place_data.get('name', '')}\" .\n",
    "\n",
    "      <https://www.wikidata.org/wiki/{place_data.get('wiki_id', '')}> rdfs:label \"{place_data.get('name', '')}\" .\n",
    "\n",
    "      <https://mbdiaries.itatti.harvard.edu/diary/1894-95/document/5/range-{uuids['uuid4']}>\n",
    "        a oa:RangeSelector;\n",
    "        oa:hasEndSelector <https://mbdiaries.itatti.harvard.edu/diary/1894-95/document/5/xpath-{uuids['uuid5']}>;\n",
    "        oa:hasStartSelector <https://mbdiaries.itatti.harvard.edu/diary/1894-95/document/5/xpath-{uuids['uuid6']}> .\n",
    "\n",
    "      <https://mbdiaries.itatti.harvard.edu/diary/1894-95/document/5/xpath-{uuids['uuid6']}>\n",
    "        a oa:XPathSelector;\n",
    "        oa:refinedBy <https://mbdiaries.itatti.harvard.edu/diary/1894-95/document/5/offset-{uuids['uuid7']}>;\n",
    "        rdf:value \"{place_data.get('line', '/p[1]')}\" .\n",
    "\n",
    "      <https://mbdiaries.itatti.harvard.edu/diary/1894-95/document/5/xpath-{uuids['uuid5']}>\n",
    "        a oa:XPathSelector;\n",
    "        oa:refinedBy <https://mbdiaries.itatti.harvard.edu/diary/1894-95/document/5/offset-{uuids['uuid3']}>;\n",
    "        rdf:value \"{place_data.get('line', '/p[1]')}\" .\n",
    "\n",
    "      <https://mbdiaries.itatti.harvard.edu/diary/1894-95/document/5/annotation-event-{uuids['uuid2']}>\n",
    "        a crmdig:D30_Annotation_Event;\n",
    "        crm:P4_has_time_span <https://mbdiaries.itatti.harvard.edu/diary/1894-95/document/5/annotation-event-{uuids['uuid2']}/modifiedAt>;\n",
    "        crm:P14_carried_out_by User:agent .\n",
    "\n",
    "      <https://mbdiaries.itatti.harvard.edu/annotation/{uuids['main']}/body>\n",
    "        a mbdiaries-ontology:Location;\n",
    "        a crm:E52_place;\n",
    "        crm:P168_place_is_defined_by \"{place_data.get('coordinates', '')}\";\n",
    "        owl:sameAs <https://www.wikidata.org/wiki/{place_data.get('wiki_id', '')}> .\n",
    "\n",
    "      <https://mbdiaries.itatti.harvard.edu/diary/1894-95/document/5/annotation-event-{uuids['uuid2']}/modifiedAt>\n",
    "        crm:P81b_begin_of_the_end \"{creation_date}\"^^xsd:dateTime;\n",
    "        crm:P81a_end_of_the_begin \"{creation_date}\"^^xsd:dateTime .\n",
    "\n",
    "      _:node1i8224na8x5257 ldp:contains <https://mbdiaries.itatti.harvard.edu/annotation/{uuids['main']}/container> .\n",
    "    }}\n",
    "\n",
    "    {{\n",
    "      _:node1i8224na8x5257 a ldp:Container, ldp:Resource, prov:Entity .\n",
    "    }}\"\"\"\n",
    "\n",
    "        return trig_template\n",
    "\n",
    "    def process_batch(self, input_directory):\n",
    "        \"\"\"Process all .txt files in the input directory\"\"\"\n",
    "        # Ensure input directory exists\n",
    "        if not os.path.exists(input_directory):\n",
    "            print(f\"Input directory {input_directory} does not exist.\")\n",
    "            return\n",
    "\n",
    "        # Create output directory if it doesn't exist\n",
    "        if not os.path.exists(self.output_dir):\n",
    "            os.makedirs(self.output_dir)\n",
    "\n",
    "        # Iterate through all .txt files in the input directory\n",
    "        for filename in os.listdir(input_directory):\n",
    "            if filename.endswith(\".txt\"):\n",
    "                filepath = os.path.join(input_directory, filename)\n",
    "                \n",
    "                try:\n",
    "                    # Read the text file\n",
    "                    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "                        text = f.read()\n",
    "\n",
    "                    # Extract places\n",
    "                    places_data = self.extract_places(text)\n",
    "\n",
    "                    if not places_data or not places_data.get(\"places\"):\n",
    "                        print(f\"No places extracted from {filename}\")\n",
    "                        continue\n",
    "\n",
    "                    # Process each place\n",
    "                    for i, place in enumerate(places_data[\"places\"]):\n",
    "                        # Convert to Trig\n",
    "                        trig_content = self.convert_to_trig(place, filename)\n",
    "\n",
    "                        # Create safe filename\n",
    "                        base_name = os.path.splitext(filename)[0]\n",
    "                        safe_place_name = \"\".join(x for x in place['name'].lower() if x.isalnum() or x in (' ', '-', '_'))\n",
    "                        \n",
    "                        # Save to file with original filename as prefix\n",
    "                        output_filename = f\"{self.output_dir}/{base_name}_place_{i+1}_{safe_place_name}.trig\"\n",
    "                        with open(output_filename, 'w', encoding='utf-8') as f:\n",
    "                            f.write(trig_content)\n",
    "                        print(f\"Processed and saved {output_filename}\")\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {filename}: {str(e)}\")\n",
    "\n",
    "def main():\n",
    "    # Initialize processor with your API key\n",
    "    api_key = ''  # Replace with your actual API key\n",
    "    processor = TextToRDFProcessor(api_key)\n",
    "\n",
    "    # Specify the input directory containing text files\n",
    "    input_directory = \"./1891/1891/txt\"  # Change this to your input directory path\n",
    "\n",
    "    # Process all text files in the directory\n",
    "    processor.process_batch(input_directory)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2hnbD_SIJjHk",
    "outputId": "e2761b1e-c29f-4f9a-93ec-5382b7b4d042"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed and saved rdf_output/100_date_1_10 jan 1872.trig\n",
      "Processed and saved rdf_output/100_date_2_16 jan 1872.trig\n",
      "Processed and saved rdf_output/100_date_3_1 sept 1873.trig\n",
      "No dates extracted from 101.txt\n",
      "Processed and saved rdf_output/102_date_1_20 jan 1876.trig\n",
      "Processed and saved rdf_output/102_date_2_3 juillet 1870.trig\n",
      "Processed and saved rdf_output/103_date_1_september 2 1891.trig\n",
      "No dates extracted from 104.txt\n",
      "No dates extracted from 105.txt\n",
      "No dates extracted from 106.txt\n",
      "Processed and saved rdf_output/107_date_1_september 3 1891.trig\n",
      "No dates extracted from 108.txt\n",
      "Processed and saved rdf_output/109_date_1_september 4 1891.trig\n",
      "Processed and saved rdf_output/110_date_1_saturday september 5 1891.trig\n",
      "Processed and saved rdf_output/111_date_1_sunday september 6 1891.trig\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 217\u001b[0m\n\u001b[0;32m    214\u001b[0m     processor\u001b[38;5;241m.\u001b[39mprocess_batch(input_directory)\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[7], line 214\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    211\u001b[0m input_directory \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./1891/1891/txt\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Change this to your input directory path\u001b[39;00m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;66;03m# Process all text files in the directory\u001b[39;00m\n\u001b[1;32m--> 214\u001b[0m \u001b[43mprocessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_directory\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[7], line 181\u001b[0m, in \u001b[0;36mTextToRDFProcessor.process_batch\u001b[1;34m(self, input_directory)\u001b[0m\n\u001b[0;32m    178\u001b[0m     text \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m    180\u001b[0m \u001b[38;5;66;03m# Extract dates\u001b[39;00m\n\u001b[1;32m--> 181\u001b[0m dates_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_dates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dates_data \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dates_data\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdates\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo dates extracted from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[7], line 38\u001b[0m, in \u001b[0;36mTextToRDFProcessor.extract_dates\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m     16\u001b[0m system_prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mYou are an AI assistant specialized in extracting dates from texts into JSON format.\u001b[39m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;124mYour task is to analyze the text and extract ONLY dates which Mary Berenson mentioned and that could be associated to a location in which she says she was, create a JSON object with these exact fields:\u001b[39m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;124m- date: date value in ISO 8601 format\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;124m    ]\u001b[39m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;124m}\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 38\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclaude-3-5-sonnet-latest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2048\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[43m        \u001b[49m\u001b[43msystem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msystem_prompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPlease analyze carefully the diary page and extract all the dates which Mary Berenson mentioned and that could be associated to a location in which she says she was. \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mtext\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m     47\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;66;03m# Extract just the JSON part from Claude's response\u001b[39;00m\n\u001b[0;32m     52\u001b[0m     response_text \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mcontent[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtext\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\anthropic\\_utils\\_utils.py:274\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    272\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    273\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 274\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\anthropic\\resources\\messages.py:878\u001b[0m, in \u001b[0;36mMessages.create\u001b[1;34m(self, max_tokens, messages, model, metadata, stop_sequences, stream, system, temperature, tool_choice, tools, top_k, top_p, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    871\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m DEPRECATED_MODELS:\n\u001b[0;32m    872\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    873\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe model \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is deprecated and will reach end-of-life on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mDEPRECATED_MODELS[model]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mPlease migrate to a newer model. Visit https://docs.anthropic.com/en/docs/resources/model-deprecations for more information.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    874\u001b[0m         \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m,\n\u001b[0;32m    875\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[0;32m    876\u001b[0m     )\n\u001b[1;32m--> 878\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/v1/messages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    882\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    883\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    884\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    885\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    886\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop_sequences\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop_sequences\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    887\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    888\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    889\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    890\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    891\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    892\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_k\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    893\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    894\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    895\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessage_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMessageCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    896\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    897\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    898\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m    899\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    900\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMessage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    901\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    902\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mRawMessageStreamEvent\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    903\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\anthropic\\_base_client.py:1260\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1246\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1247\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1248\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1255\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1256\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1257\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1258\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1259\u001b[0m     )\n\u001b[1;32m-> 1260\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\anthropic\\_base_client.py:937\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    928\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[0;32m    929\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    930\u001b[0m     cast_to: Type[ResponseT],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    935\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    936\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m--> 937\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    938\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    939\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    940\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    941\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    942\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    943\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\anthropic\\_base_client.py:973\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    970\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSending HTTP Request: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, request\u001b[38;5;241m.\u001b[39mmethod, request\u001b[38;5;241m.\u001b[39murl)\n\u001b[0;32m    972\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 973\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39msend(\n\u001b[0;32m    974\u001b[0m         request,\n\u001b[0;32m    975\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_stream_response_body(request\u001b[38;5;241m=\u001b[39mrequest),\n\u001b[0;32m    976\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    977\u001b[0m     )\n\u001b[0;32m    978\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    979\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered httpx.TimeoutException\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpx\\_client.py:926\u001b[0m, in \u001b[0;36mClient.send\u001b[1;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[0;32m    922\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_timeout(request)\n\u001b[0;32m    924\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[1;32m--> 926\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    929\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    930\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    931\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    932\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    933\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpx\\_client.py:954\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[1;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[0;32m    951\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[0;32m    953\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 954\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    955\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    956\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    957\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    959\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    960\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpx\\_client.py:991\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[1;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[0;32m    988\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    989\u001b[0m     hook(request)\n\u001b[1;32m--> 991\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    992\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    993\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpx\\_client.py:1027\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1023\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1024\u001b[0m     )\n\u001b[0;32m   1026\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[1;32m-> 1027\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1029\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[0;32m   1031\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpx\\_transports\\default.py:236\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    223\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[0;32m    224\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m    225\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    233\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[0;32m    234\u001b[0m )\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[1;32m--> 236\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[0;32m    241\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[0;32m    242\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m    243\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[0;32m    244\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[0;32m    245\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpcore\\_sync\\connection_pool.py:216\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    213\u001b[0m         closing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_requests_to_connections()\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[1;32m--> 216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, Iterable)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpcore\\_sync\\connection_pool.py:196\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    192\u001b[0m connection \u001b[38;5;241m=\u001b[39m pool_request\u001b[38;5;241m.\u001b[39mwait_for_connection(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[1;32m--> 196\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[0;32m    202\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[0;32m    204\u001b[0m     pool_request\u001b[38;5;241m.\u001b[39mclear_connection()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpcore\\_sync\\connection.py:101\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[1;32m--> 101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpcore\\_sync\\http11.py:143\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[1;32m--> 143\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpcore\\_sync\\http11.py:113\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[0;32m    106\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[0;32m    107\u001b[0m     (\n\u001b[0;32m    108\u001b[0m         http_version,\n\u001b[0;32m    109\u001b[0m         status,\n\u001b[0;32m    110\u001b[0m         reason_phrase,\n\u001b[0;32m    111\u001b[0m         headers,\n\u001b[0;32m    112\u001b[0m         trailing_data,\n\u001b[1;32m--> 113\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_receive_response_headers(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    114\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    115\u001b[0m         http_version,\n\u001b[0;32m    116\u001b[0m         status,\n\u001b[0;32m    117\u001b[0m         reason_phrase,\n\u001b[0;32m    118\u001b[0m         headers,\n\u001b[0;32m    119\u001b[0m     )\n\u001b[0;32m    121\u001b[0m network_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpcore\\_sync\\http11.py:186\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    183\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 186\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[0;32m    188\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpcore\\_sync\\http11.py:224\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    221\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[1;32m--> 224\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m    226\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    230\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    234\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[0;32m    236\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpcore\\_backends\\sync.py:126\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[1;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[1;32m--> 126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\ssl.py:1259\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[1;34m(self, buflen, flags)\u001b[0m\n\u001b[0;32m   1255\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1256\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1257\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1258\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1259\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1260\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1261\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\ssl.py:1132\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1130\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[0;32m   1131\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1132\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1133\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[0;32m   1134\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import uuid\n",
    "import anthropic\n",
    "from datetime import datetime\n",
    "\n",
    "class TextToRDFProcessor:\n",
    "    def __init__(self, api_key):\n",
    "        self.client = anthropic.Anthropic(api_key=api_key)\n",
    "        self.output_dir = \"rdf_output\"\n",
    "        if not os.path.exists(self.output_dir):\n",
    "            os.makedirs(self.output_dir)\n",
    "\n",
    "    def extract_dates(self, text):\n",
    "        \"\"\"Extract places from text using Claude API\"\"\"\n",
    "        system_prompt = \"\"\"You are an AI assistant specialized in extracting dates from texts into JSON format.\n",
    "        Your task is to analyze the text and extract ONLY dates which Mary Berenson mentioned and that could be associated to a location in which she says she was, create a JSON object with these exact fields:\n",
    "        - date: date value in ISO 8601 format\n",
    "        - name: name of the date\n",
    "        - line: text line reference in format /p[N] where N is line number\n",
    "        - start_position: character position where date mention starts: Offset resets after each line, so first character of the second line will have start_position = 0\n",
    "        - end_position: character position where date mention ends. Offset resets after each line.\n",
    "\n",
    "        Return the results in this exact format, with no additional text:\n",
    "        {\n",
    "            \"dates\": [\n",
    "                {\n",
    "                    \"name\": \"25th September 2023\",\n",
    "                    \"date\": \"2023-09-25T00:00:00:000Z\",\n",
    "                    \"start_position\": \"23\",\n",
    "                    \"end_position\": \"35\",\n",
    "                    \"line\": \"/p[1]\"\n",
    "                }\n",
    "            ]\n",
    "        }\"\"\"\n",
    "\n",
    "        try:\n",
    "            response = self.client.messages.create(\n",
    "                model=\"claude-3-5-sonnet-latest\",\n",
    "                max_tokens=2048,\n",
    "                system=system_prompt,\n",
    "                temperature=0,\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": f\"Please analyze carefully the diary page and extract all the dates which Mary Berenson mentioned and that could be associated to a location in which she says she was. \\n\\n{text}\"\n",
    "                    }\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            # Extract just the JSON part from Claude's response\n",
    "            response_text = response.content[0].text\n",
    "\n",
    "            # Find the JSON object bounds\n",
    "            start_idx = response_text.find('{')\n",
    "            end_idx = response_text.rfind('}') + 1\n",
    "\n",
    "            if start_idx == -1 or end_idx == 0:\n",
    "                raise ValueError(\"No valid JSON found in response\")\n",
    "\n",
    "            json_str = response_text[start_idx:end_idx]\n",
    "\n",
    "            # Parse the JSON\n",
    "            dates_data = json.loads(json_str)\n",
    "\n",
    "            # Validate the structure\n",
    "            if \"dates\" not in dates_data:\n",
    "                dates_data = {\"dates\": [dates_data]}\n",
    "\n",
    "            return dates_data\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting dates: {str(e)}\")\n",
    "            print(f\"Raw response: {response_text}\")\n",
    "            return None\n",
    "\n",
    "    def generate_uuids(self):\n",
    "        \"\"\"Generate a set of UUIDs for use in the Trig template\"\"\"\n",
    "        return {\n",
    "            'main': str(uuid.uuid4()),\n",
    "            'uuid2': str(uuid.uuid4()),\n",
    "            'uuid3': str(uuid.uuid4()),\n",
    "            'uuid4': str(uuid.uuid4()),\n",
    "            'uuid5': str(uuid.uuid4()),\n",
    "            'uuid6': str(uuid.uuid4()),\n",
    "            'uuid7': str(uuid.uuid4())\n",
    "        }\n",
    "\n",
    "    def convert_to_trig(self, date_data, input_filename):\n",
    "        \"\"\"Convert a single date data to Trig format\"\"\"\n",
    "        uuids = self.generate_uuids()\n",
    "        creation_date = datetime.now().isoformat()\n",
    "\n",
    "        trig_template = f\"\"\"<https://mbdiaries.itatti.harvard.edu/annotation/{uuids['main']}/container/context> {{\n",
    "      <https://mbdiaries.itatti.harvard.edu/diary/1894-95/document/5/offset-{uuids['uuid7']}>\n",
    "        a oa:TextPositionSelector;\n",
    "        oa:end \"{date_data.get('start_position', '')}\"^^xsd:nonNegativeInteger;\n",
    "        oa:start \"{date_data.get('start_position', '')}\"^^xsd:nonNegativeInteger .\n",
    "\n",
    "      <https://mbdiaries.itatti.harvard.edu/diary/1894-95/document/5/offset-{uuids['uuid3']}>\n",
    "        a oa:TextPositionSelector;\n",
    "        oa:end \"{date_data.get('end_position', '')}\"^^xsd:nonNegativeInteger;\n",
    "        oa:start \"{date_data.get('end_position', '')}\"^^xsd:nonNegativeInteger .\n",
    "\n",
    "      mbdiaries-annotation:{uuids['main']} a oa:Annotation, crmdig:D29_Annotation_Object;\n",
    "        crmdig:L48i_was_annotation_created_by <https://mbdiaries.itatti.harvard.edu/diary/1894-95/document/5/annotation-event-{uuids['uuid2']}>;\n",
    "        oa:hasBody <https://mbdiaries.itatti.harvard.edu/annotation/{uuids['main']}/body>;\n",
    "        oa:hasTarget <https://mbdiaries.itatti.harvard.edu/diary/1894-95/document/5/range-source-{uuids['uuid4']}> .\n",
    "\n",
    "      <https://mbdiaries.itatti.harvard.edu/annotation/{uuids['main']}/container>\n",
    "        a ldp:Resource, prov:Entity;\n",
    "        prov:wasAttributedTo User:agent;\n",
    "        prov:generatedAtTime \"{creation_date}\"^^xsd:dateTime .\n",
    "\n",
    "      <https://mbdiaries.itatti.harvard.edu/diary/1894-95/document/5/range-source-{uuids['uuid4']}>\n",
    "        a oa:SpecificResource;\n",
    "        oa:hasSource <https://mbdiaries.itatti.harvard.edu/diary/1894-95/document/5>;\n",
    "        oa:hasSelector <https://mbdiaries.itatti.harvard.edu/diary/1894-95/document/5/range-{uuids['uuid4']}>;\n",
    "        rdf:value \"{date_data.get('name', '')}\" .\n",
    "\n",
    "      <https://mbdiaries.itatti.harvard.edu/diary/1894-95/document/5/range-{uuids['uuid4']}>\n",
    "        a oa:RangeSelector;\n",
    "        oa:hasEndSelector <https://mbdiaries.itatti.harvard.edu/diary/1894-95/document/5/xpath-{uuids['uuid5']}>;\n",
    "        oa:hasStartSelector <https://mbdiaries.itatti.harvard.edu/diary/1894-95/document/5/xpath-{uuids['uuid6']}> .\n",
    "\n",
    "      <https://mbdiaries.itatti.harvard.edu/diary/1894-95/document/5/xpath-{uuids['uuid6']}>\n",
    "        a oa:XPathSelector;\n",
    "        oa:refinedBy <https://mbdiaries.itatti.harvard.edu/diary/1894-95/document/5/offset-{uuids['uuid7']}>;\n",
    "        rdf:value \"{date_data.get('line', '/p[1]')}\" .\n",
    "\n",
    "      <https://mbdiaries.itatti.harvard.edu/diary/1894-95/document/5/xpath-{uuids['uuid5']}>\n",
    "        a oa:XPathSelector;\n",
    "        oa:refinedBy <https://mbdiaries.itatti.harvard.edu/diary/1894-95/document/5/offset-{uuids['uuid3']}>;\n",
    "        rdf:value \"{date_data.get('line', '/p[1]')}\" .\n",
    "\n",
    "      <https://mbdiaries.itatti.harvard.edu/diary/1894-95/document/5/annotation-event-{uuids['uuid2']}>\n",
    "        a crmdig:D30_Annotation_Event;\n",
    "        crm:P4_has_time_span <https://mbdiaries.itatti.harvard.edu/diary/1894-95/document/5/annotation-event-{uuids['uuid2']}/modifiedAt>;\n",
    "        crm:P14_carried_out_by User:agent .\n",
    "\n",
    "      <https://mbdiaries.itatti.harvard.edu/annotation/{uuids['main']}/body>\n",
    "        a mbdiaries-ontology:Location;\n",
    "        a crm:E52_time_span;\n",
    "        crm:P181b_begin_of_the_end \"{date_data.get('date', \"\")}\"^^xsd:dateTime.\n",
    "\n",
    "      <https://mbdiaries.itatti.harvard.edu/diary/1894-95/document/5/annotation-event-{uuids['uuid2']}/modifiedAt>\n",
    "        crm:P81b_begin_of_the_end \"{creation_date}\"^^xsd:dateTime;\n",
    "        crm:P81a_end_of_the_begin \"{creation_date}\"^^xsd:dateTime .\n",
    "\n",
    "      _:node1i8224na8x5257 ldp:contains <https://mbdiaries.itatti.harvard.edu/annotation/{uuids['main']}/container> .\n",
    "    }}\n",
    "\n",
    "    {{\n",
    "      _:node1i8224na8x5257 a ldp:Container, ldp:Resource, prov:Entity .\n",
    "    }}\"\"\"\n",
    "\n",
    "        return trig_template\n",
    "\n",
    "    def process_batch(self, input_directory):\n",
    "        \"\"\"Process all .txt files in the input directory\"\"\"\n",
    "        # Ensure input directory exists\n",
    "        if not os.path.exists(input_directory):\n",
    "            print(f\"Input directory {input_directory} does not exist.\")\n",
    "            return\n",
    "\n",
    "        # Create output directory if it doesn't exist\n",
    "        if not os.path.exists(self.output_dir):\n",
    "            os.makedirs(self.output_dir)\n",
    "\n",
    "        # Iterate through all .txt files in the input directory\n",
    "        for filename in os.listdir(input_directory):\n",
    "            if filename.endswith(\".txt\"):\n",
    "                filepath = os.path.join(input_directory, filename)\n",
    "                \n",
    "                try:\n",
    "                    # Read the text file\n",
    "                    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "                        text = f.read()\n",
    "\n",
    "                    # Extract dates\n",
    "                    dates_data = self.extract_dates(text)\n",
    "\n",
    "                    if not dates_data or not dates_data.get(\"dates\"):\n",
    "                        print(f\"No dates extracted from {filename}\")\n",
    "                        continue\n",
    "\n",
    "                    # Process each date\n",
    "                    for i, date in enumerate(dates_data[\"dates\"]):\n",
    "                        # Convert to Trig\n",
    "                        trig_content = self.convert_to_trig(date, filename)\n",
    "\n",
    "                        # Create safe filename\n",
    "                        base_name = os.path.splitext(filename)[0]\n",
    "                        safe_date_name = \"\".join(x for x in date['name'].lower() if x.isalnum() or x in (' ', '-', '_'))\n",
    "                        \n",
    "                        # Save to file with original filename as prefix\n",
    "                        output_filename = f\"{self.output_dir}/{base_name}_date_{i+1}_{safe_date_name}.trig\"\n",
    "                        with open(output_filename, 'w', encoding='utf-8') as f:\n",
    "                            f.write(trig_content)\n",
    "                        print(f\"Processed and saved {output_filename}\")\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {filename}: {str(e)}\")\n",
    "\n",
    "def main():\n",
    "    # Initialize processor with your API key\n",
    "    api_key = ''  # Replace with your actual API key\n",
    "    processor = TextToRDFProcessor(api_key)\n",
    "\n",
    "    # Specify the input directory containing text files\n",
    "    input_directory = \"./1891/1891/txt\"  # Change this to your input directory path\n",
    "\n",
    "    # Process all text files in the directory\n",
    "    processor.process_batch(input_directory)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gi67ACuUKbE8",
    "outputId": "d25fa50c-c4a7-4397-8ca6-cb4ffcf86836"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping 100: No matching trig files found\n",
      "Skipping 101: No matching trig files found\n",
      "Saved Trig file: rdf_output\\102_event_e4a8d0c6-f8c4-4c9d-9d7f-1a3b5c2a7d9a.trig\n",
      "\n",
      "Processed 102:\n",
      "\n",
      "Event: Lake Garda, 20 January 1876\n",
      "Place UUID: 3e93d1af-cb54-4816-bdc3-d363bee29773\n",
      "Date UUID: 0c0195e4-2590-444a-821d-86364bca9e77\n",
      "Event UUID: e4a8d0c6-f8c4-4c9d-9d7f-1a3b5c2a7d9a\n",
      "Next Event: Ratisbon, 23 September 1900\n",
      "Next Event UUID: d8d7f9c0-6d4f-4d9f-9f9f-e9d6d8f9d9d9\n",
      "Saved Trig file: rdf_output\\103_event_d8d7f9c0-6d4f-4d9f-9f9f-e9d6d8f9d9d9.trig\n",
      "Saved Trig file: rdf_output\\103_event_f7a6e2c1-b9b0-4f9a-8d8d-f9d9d9d9f9f9.trig\n",
      "Saved Trig file: rdf_output\\103_event_d9d9f9f9-f9f9-f9d9-9d9d-9f9f9d9d9d9d.trig\n",
      "\n",
      "Processed 103:\n",
      "\n",
      "Event: Ratisbon, 23 September 1900\n",
      "Place UUID: e4f5dde1-881f-450d-a754-8486fb8e5b2b\n",
      "Date UUID: 6bce0e16-56ca-4383-8273-875c0ab5670e\n",
      "Event UUID: d8d7f9c0-6d4f-4d9f-9f9f-e9d6d8f9d9d9\n",
      "Next Event: Schottenkirche, 23 September 1900\n",
      "Next Event UUID: f7a6e2c1-b9b0-4f9a-8d8d-f9d9d9d9f9f9\n",
      "\n",
      "Event: Schottenkirche, 23 September 1900\n",
      "Place UUID: ab4b3140-6fea-4a6b-8baf-162ba46d81c1\n",
      "Date UUID: 6bce0e16-56ca-4383-8273-875c0ab5670e\n",
      "Event UUID: f7a6e2c1-b9b0-4f9a-8d8d-f9d9d9d9f9f9\n",
      "Next Event: Cathedral of Regensburg, 23 September 1900\n",
      "Next Event UUID: d9d9f9f9-f9f9-f9d9-9d9d-9f9f9d9d9d9d\n",
      "\n",
      "Event: Cathedral of Regensburg, 23 September 1900\n",
      "Place UUID: ad1fbf18-b341-41fa-8318-ed8a45bf014b\n",
      "Date UUID: 6bce0e16-56ca-4383-8273-875c0ab5670e\n",
      "Event UUID: d9d9f9f9-f9f9-f9d9-9d9d-9f9f9d9d9d9d\n",
      "Next Event: None\n",
      "Next Event UUID: None\n",
      "Skipping 104: No matching trig files found\n",
      "Skipping 105: No matching trig files found\n",
      "Skipping 106: No matching trig files found\n",
      "Saved Trig file: rdf_output\\107_event_e1234567-e89b-12d3-a456-426614174000.trig\n",
      "Saved Trig file: rdf_output\\107_event_e8901234-5678-9012-3456-789012345678.trig\n",
      "Saved Trig file: rdf_output\\107_event_e1a2b3c4-d5e6-f789-0123-456789012345.trig\n",
      "Saved Trig file: rdf_output\\107_event_e6f7a8b9-c0d1-2345-6789-012345678901.trig\n",
      "\n",
      "Processed 107:\n",
      "\n",
      "Event: Regensburg, 3 September 1891\n",
      "Place UUID: d18fa026-0a79-415f-8bd0-10fba4e06ac3\n",
      "Date UUID: b0a41463-569f-4c1e-b692-9c507c3100e9\n",
      "Event UUID: e1234567-e89b-12d3-a456-426614174000\n",
      "Next Event: Munich, 3 September 1891\n",
      "Next Event UUID: e8901234-5678-9012-3456-789012345678\n",
      "\n",
      "Event: Munich, 3 September 1891\n",
      "Place UUID: cf21e520-8fec-4fdb-ab9f-2132e89b4fb1\n",
      "Date UUID: b0a41463-569f-4c1e-b692-9c507c3100e9\n",
      "Event UUID: e8901234-5678-9012-3456-789012345678\n",
      "Next Event: Pinacothek, 3 September 1891\n",
      "Next Event UUID: e1a2b3c4-d5e6-f789-0123-456789012345\n",
      "\n",
      "Event: Pinacothek, 3 September 1891\n",
      "Place UUID: f0c428c2-92e5-45d8-9578-d5d81fd7e80a\n",
      "Date UUID: b0a41463-569f-4c1e-b692-9c507c3100e9\n",
      "Event UUID: e1a2b3c4-d5e6-f789-0123-456789012345\n",
      "Next Event: Glaspalast, 3 September 1891\n",
      "Next Event UUID: e6f7a8b9-c0d1-2345-6789-012345678901\n",
      "\n",
      "Event: Glaspalast, 3 September 1891\n",
      "Place UUID: 58520d5f-d302-421b-b369-73209403a77b\n",
      "Date UUID: b0a41463-569f-4c1e-b692-9c507c3100e9\n",
      "Event UUID: e6f7a8b9-c0d1-2345-6789-012345678901\n",
      "Next Event: Munich, 4 September 1891\n",
      "Next Event UUID: e4b2d7c3-f8f4-4a6e-9d9f-5a6c1e6d6b0a\n",
      "Skipping 108: No matching trig files found\n",
      "Saved Trig file: rdf_output\\109_event_e4b2d7c3-f8f4-4a6e-9d9f-5a6c1e6d6b0a.trig\n",
      "\n",
      "Processed 109:\n",
      "\n",
      "Event: Munich, 4 September 1891\n",
      "Place UUID: b2df5f3b-ab34-4d63-a2d2-d118982d340e\n",
      "Date UUID: 50230425-1fd7-4778-93ff-6d2077e1676e\n",
      "Event UUID: e4b2d7c3-f8f4-4a6e-9d9f-5a6c1e6d6b0a\n",
      "Next Event: Munich, 5 September 1891\n",
      "Next Event UUID: 3e1d2d0a-f9a2-4f93-8ead-38f1f12d6e34\n",
      "Saved Trig file: rdf_output\\110_event_3e1d2d0a-f9a2-4f93-8ead-38f1f12d6e34.trig\n",
      "\n",
      "Processed 110:\n",
      "\n",
      "Event: Munich, 5 September 1891\n",
      "Place UUID: eb4c4f1f-3c79-43ec-bc1c-3a25aa2654fa\n",
      "Date UUID: 56fddba6-a2e5-429a-beb9-d8ca806948b6\n",
      "Event UUID: 3e1d2d0a-f9a2-4f93-8ead-38f1f12d6e34\n",
      "Next Event: Munich, 6 September 1891\n",
      "Next Event UUID: e7b2d7c4-f9d4-4f9f-9f9d-a8f6a9d4e5c1\n",
      "Saved Trig file: rdf_output\\111_event_e7b2d7c4-f9d4-4f9f-9f9d-a8f6a9d4e5c1.trig\n",
      "\n",
      "Processed 111:\n",
      "\n",
      "Event: Munich, 6 September 1891\n",
      "Place UUID: 208a6fd8-fcb7-4452-beef-9b66c6ab0193\n",
      "Date UUID: 7a1aa825-68bb-4b03-8fc7-e3282df1ce1c\n",
      "Event UUID: e7b2d7c4-f9d4-4f9f-9f9d-a8f6a9d4e5c1\n",
      "Next Event: Pinacothek, 6 September 1891\n",
      "Next Event UUID: f8e4a7d2-9a3b-4d8f-b9c6-0c7f7d5d3f7a\n",
      "Skipping 112: No matching trig files found\n",
      "Skipping 113: No matching trig files found\n",
      "Skipping 114: No matching trig files found\n",
      "Skipping 115: No matching trig files found\n",
      "Skipping 116: No matching trig files found\n",
      "Skipping 117: No matching trig files found\n",
      "Skipping 118: No matching trig files found\n",
      "Skipping 120: No matching trig files found\n",
      "Skipping 121: No matching trig files found\n",
      "Skipping 122: No matching trig files found\n",
      "Skipping 123: No matching trig files found\n",
      "Skipping 124: No matching trig files found\n",
      "Skipping 125: No matching trig files found\n",
      "Skipping 126: No matching trig files found\n",
      "Skipping 127: No matching trig files found\n",
      "Skipping 128: No matching trig files found\n",
      "Skipping 129: No matching trig files found\n",
      "Skipping 130: No matching trig files found\n",
      "Skipping 131: No matching trig files found\n",
      "Skipping 132: No matching trig files found\n",
      "Skipping 133: No matching trig files found\n",
      "Skipping 134: No matching trig files found\n",
      "Skipping 135: No matching trig files found\n",
      "Skipping 136: No matching trig files found\n",
      "Skipping 137: No matching trig files found\n",
      "Skipping 138: No matching trig files found\n",
      "Skipping 139: No matching trig files found\n",
      "Skipping 140: No matching trig files found\n",
      "Skipping 141: No matching trig files found\n",
      "Skipping 142: No matching trig files found\n",
      "Skipping 143: No matching trig files found\n",
      "Skipping 144: No matching trig files found\n",
      "Skipping 146: No matching trig files found\n",
      "Skipping 147: No matching trig files found\n",
      "Skipping 148: No matching trig files found\n",
      "Skipping 149: No matching trig files found\n",
      "Skipping 15: No matching trig files found\n",
      "Skipping 150: No matching trig files found\n",
      "Skipping 151: No matching trig files found\n",
      "Skipping 152: No matching trig files found\n",
      "Skipping 153: No matching trig files found\n",
      "Skipping 154: No matching trig files found\n",
      "Skipping 155: No matching trig files found\n",
      "Skipping 156: No matching trig files found\n",
      "Skipping 157: No matching trig files found\n",
      "Skipping 158: No matching trig files found\n",
      "Skipping 159: No matching trig files found\n",
      "Skipping 16: No matching trig files found\n",
      "Skipping 160: No matching trig files found\n",
      "Skipping 161: No matching trig files found\n",
      "Skipping 162: No matching trig files found\n",
      "Skipping 163: No matching trig files found\n",
      "Skipping 164: No matching trig files found\n",
      "Skipping 165: No matching trig files found\n",
      "Skipping 166: No matching trig files found\n",
      "Skipping 167: No matching trig files found\n",
      "Skipping 168: No matching trig files found\n",
      "Skipping 169: No matching trig files found\n",
      "Skipping 17: No matching trig files found\n",
      "Skipping 170: No matching trig files found\n",
      "Skipping 171: No matching trig files found\n",
      "Skipping 172: No matching trig files found\n",
      "Skipping 174: No matching trig files found\n",
      "Skipping 175: No matching trig files found\n",
      "Skipping 176: No matching trig files found\n",
      "Skipping 177: No matching trig files found\n",
      "Skipping 178: No matching trig files found\n",
      "Skipping 179: No matching trig files found\n",
      "Skipping 18: No matching trig files found\n",
      "Skipping 180: No matching trig files found\n",
      "Skipping 181: No matching trig files found\n",
      "Skipping 182: No matching trig files found\n",
      "Skipping 184: No matching trig files found\n",
      "Skipping 185: No matching trig files found\n",
      "Skipping 186: No matching trig files found\n",
      "Skipping 187: No matching trig files found\n",
      "Skipping 188: No matching trig files found\n",
      "Skipping 189: No matching trig files found\n",
      "Skipping 19: No matching trig files found\n",
      "Skipping 190: No matching trig files found\n",
      "Skipping 191: No matching trig files found\n",
      "Skipping 192: No matching trig files found\n",
      "Skipping 193: No matching trig files found\n",
      "Skipping 194: No matching trig files found\n",
      "Skipping 195: No matching trig files found\n",
      "Skipping 196: No matching trig files found\n",
      "Skipping 197: No matching trig files found\n",
      "Skipping 198: No matching trig files found\n",
      "Skipping 199: No matching trig files found\n",
      "Skipping 2: No matching trig files found\n",
      "Skipping 20: No matching trig files found\n",
      "Skipping 200: No matching trig files found\n",
      "Skipping 201: No matching trig files found\n",
      "Skipping 202: No matching trig files found\n",
      "Skipping 204: No matching trig files found\n",
      "Skipping 205: No matching trig files found\n",
      "Skipping 206: No matching trig files found\n",
      "Skipping 207: No matching trig files found\n",
      "Skipping 208: No matching trig files found\n",
      "Skipping 209: No matching trig files found\n",
      "Skipping 21: No matching trig files found\n",
      "Skipping 210: No matching trig files found\n",
      "Skipping 211: No matching trig files found\n",
      "Skipping 212: No matching trig files found\n",
      "Skipping 213: No matching trig files found\n",
      "Skipping 214: No matching trig files found\n",
      "Skipping 215: No matching trig files found\n",
      "Skipping 216: No matching trig files found\n",
      "Skipping 217: No matching trig files found\n",
      "Skipping 218: No matching trig files found\n",
      "Skipping 219: No matching trig files found\n",
      "Skipping 220: No matching trig files found\n",
      "Skipping 221: No matching trig files found\n",
      "Skipping 222: No matching trig files found\n",
      "Skipping 223: No matching trig files found\n",
      "Skipping 224: No matching trig files found\n",
      "Skipping 225: No matching trig files found\n",
      "Skipping 226: No matching trig files found\n",
      "Skipping 227: No matching trig files found\n",
      "Skipping 228: No matching trig files found\n",
      "Skipping 229: No matching trig files found\n",
      "Skipping 230: No matching trig files found\n",
      "Skipping 231: No matching trig files found\n",
      "Skipping 232: No matching trig files found\n",
      "Skipping 233: No matching trig files found\n",
      "Skipping 235: No matching trig files found\n",
      "Skipping 237: No matching trig files found\n",
      "Skipping 238: No matching trig files found\n",
      "Skipping 239: No matching trig files found\n",
      "Skipping 240: No matching trig files found\n",
      "Skipping 241: No matching trig files found\n",
      "Skipping 242: No matching trig files found\n",
      "Skipping 243: No matching trig files found\n",
      "Skipping 244: No matching trig files found\n",
      "Skipping 245: No matching trig files found\n",
      "Skipping 246: No matching trig files found\n",
      "Skipping 247: No matching trig files found\n",
      "Skipping 248: No matching trig files found\n",
      "Skipping 249: No matching trig files found\n",
      "Skipping 250: No matching trig files found\n",
      "Skipping 251: No matching trig files found\n",
      "Skipping 252: No matching trig files found\n",
      "Skipping 253: No matching trig files found\n",
      "Skipping 254: No matching trig files found\n",
      "Skipping 255: No matching trig files found\n",
      "Skipping 256: No matching trig files found\n",
      "Skipping 257: No matching trig files found\n",
      "Skipping 258: No matching trig files found\n",
      "Skipping 259: No matching trig files found\n",
      "Skipping 260: No matching trig files found\n",
      "Skipping 261: No matching trig files found\n",
      "Skipping 262: No matching trig files found\n",
      "Skipping 263: No matching trig files found\n",
      "Skipping 264: No matching trig files found\n",
      "Skipping 265: No matching trig files found\n",
      "Skipping 266: No matching trig files found\n",
      "Skipping 267: No matching trig files found\n",
      "Skipping 268: No matching trig files found\n",
      "Skipping 269: No matching trig files found\n",
      "Skipping 270: No matching trig files found\n",
      "Skipping 271: No matching trig files found\n",
      "Skipping 272: No matching trig files found\n",
      "Skipping 273: No matching trig files found\n",
      "Skipping 274: No matching trig files found\n",
      "Skipping 275: No matching trig files found\n",
      "Skipping 276: No matching trig files found\n",
      "Skipping 277: No matching trig files found\n",
      "Skipping 278: No matching trig files found\n",
      "Skipping 279: No matching trig files found\n",
      "Skipping 280: No matching trig files found\n",
      "Skipping 281: No matching trig files found\n",
      "Skipping 282: No matching trig files found\n",
      "Skipping 283: No matching trig files found\n",
      "Skipping 284: No matching trig files found\n",
      "Skipping 285: No matching trig files found\n",
      "Skipping 286: No matching trig files found\n",
      "Skipping 287: No matching trig files found\n",
      "Skipping 288: No matching trig files found\n",
      "Skipping 289: No matching trig files found\n",
      "Skipping 290: No matching trig files found\n",
      "Skipping 291: No matching trig files found\n",
      "Skipping 292: No matching trig files found\n",
      "Skipping 293: No matching trig files found\n",
      "Skipping 294: No matching trig files found\n",
      "Skipping 295: No matching trig files found\n",
      "Skipping 296: No matching trig files found\n",
      "Skipping 297: No matching trig files found\n",
      "Skipping 298: No matching trig files found\n",
      "Skipping 299: No matching trig files found\n",
      "Skipping 300: No matching trig files found\n",
      "Skipping 301: No matching trig files found\n",
      "Skipping 302: No matching trig files found\n",
      "Skipping 303: No matching trig files found\n",
      "Skipping 304: No matching trig files found\n",
      "Skipping 305: No matching trig files found\n",
      "Skipping 306: No matching trig files found\n",
      "Skipping 307: No matching trig files found\n",
      "Skipping 308: No matching trig files found\n",
      "Skipping 309: No matching trig files found\n",
      "Skipping 310: No matching trig files found\n",
      "Skipping 311: No matching trig files found\n",
      "Skipping 312: No matching trig files found\n",
      "Skipping 313: No matching trig files found\n",
      "Skipping 314: No matching trig files found\n",
      "Skipping 315: No matching trig files found\n",
      "Skipping 316: No matching trig files found\n",
      "Skipping 317: No matching trig files found\n",
      "Skipping 318: No matching trig files found\n",
      "Skipping 319: No matching trig files found\n",
      "Skipping 320: No matching trig files found\n",
      "Skipping 321: No matching trig files found\n",
      "Skipping 322: No matching trig files found\n",
      "Skipping 323: No matching trig files found\n",
      "Skipping 324: No matching trig files found\n",
      "Skipping 325: No matching trig files found\n",
      "Skipping 326: No matching trig files found\n",
      "Skipping 327: No matching trig files found\n",
      "Skipping 329: No matching trig files found\n",
      "Skipping 330: No matching trig files found\n",
      "Skipping 331: No matching trig files found\n",
      "Skipping 332: No matching trig files found\n",
      "Skipping 333: No matching trig files found\n",
      "Skipping 334: No matching trig files found\n",
      "Skipping 335: No matching trig files found\n",
      "Skipping 336: No matching trig files found\n",
      "Skipping 337: No matching trig files found\n",
      "Skipping 338: No matching trig files found\n",
      "Skipping 340: No matching trig files found\n",
      "Skipping 341: No matching trig files found\n",
      "Skipping 342: No matching trig files found\n",
      "Skipping 343: No matching trig files found\n",
      "Skipping 344: No matching trig files found\n",
      "Skipping 345: No matching trig files found\n",
      "Skipping 346: No matching trig files found\n",
      "Skipping 347: No matching trig files found\n",
      "Skipping 348: No matching trig files found\n",
      "Skipping 349: No matching trig files found\n",
      "Skipping 350: No matching trig files found\n",
      "Skipping 351: No matching trig files found\n",
      "Skipping 352: No matching trig files found\n",
      "Skipping 353: No matching trig files found\n",
      "Skipping 354: No matching trig files found\n",
      "Skipping 355: No matching trig files found\n",
      "Skipping 356: No matching trig files found\n",
      "Skipping 357: No matching trig files found\n",
      "Skipping 358: No matching trig files found\n",
      "Skipping 359: No matching trig files found\n",
      "Skipping 360: No matching trig files found\n",
      "Skipping 361: No matching trig files found\n",
      "Skipping 362: No matching trig files found\n",
      "Skipping 363: No matching trig files found\n",
      "Skipping 364: No matching trig files found\n",
      "Skipping 365: No matching trig files found\n",
      "Skipping 366: No matching trig files found\n",
      "Skipping 367: No matching trig files found\n",
      "Skipping 368: No matching trig files found\n",
      "Skipping 369: No matching trig files found\n",
      "Skipping 370: No matching trig files found\n",
      "Skipping 371: No matching trig files found\n",
      "Skipping 372: No matching trig files found\n",
      "Skipping 373: No matching trig files found\n",
      "Skipping 374: No matching trig files found\n",
      "Skipping 375: No matching trig files found\n",
      "Skipping 376: No matching trig files found\n",
      "Skipping 377: No matching trig files found\n",
      "Skipping 378: No matching trig files found\n",
      "Skipping 379: No matching trig files found\n",
      "Skipping 380: No matching trig files found\n",
      "Skipping 381: No matching trig files found\n",
      "Skipping 382: No matching trig files found\n",
      "Skipping 383: No matching trig files found\n",
      "Skipping 384: No matching trig files found\n",
      "Skipping 385: No matching trig files found\n",
      "Skipping 386: No matching trig files found\n",
      "Skipping 387: No matching trig files found\n",
      "Skipping 388: No matching trig files found\n",
      "Skipping 389: No matching trig files found\n",
      "Skipping 390: No matching trig files found\n",
      "Skipping 391: No matching trig files found\n",
      "Skipping 392: No matching trig files found\n",
      "Skipping 393: No matching trig files found\n",
      "Skipping 394: No matching trig files found\n",
      "Skipping 395: No matching trig files found\n",
      "Skipping 396: No matching trig files found\n",
      "Skipping 397: No matching trig files found\n",
      "Skipping 398: No matching trig files found\n",
      "Skipping 399: No matching trig files found\n",
      "Skipping 400: No matching trig files found\n",
      "Skipping 401: No matching trig files found\n",
      "Skipping 402: No matching trig files found\n",
      "Skipping 403: No matching trig files found\n",
      "Skipping 404: No matching trig files found\n",
      "Skipping 405: No matching trig files found\n",
      "Skipping 406: No matching trig files found\n",
      "Skipping 407: No matching trig files found\n",
      "Skipping 408: No matching trig files found\n",
      "Skipping 409: No matching trig files found\n",
      "Skipping 410: No matching trig files found\n",
      "Skipping 411: No matching trig files found\n",
      "Skipping 412: No matching trig files found\n",
      "Skipping 413: No matching trig files found\n",
      "Skipping 414: No matching trig files found\n",
      "Skipping 415: No matching trig files found\n",
      "Skipping 416: No matching trig files found\n",
      "Skipping 417: No matching trig files found\n",
      "Skipping 418: No matching trig files found\n",
      "Skipping 419: No matching trig files found\n",
      "Skipping 420: No matching trig files found\n",
      "Skipping 421: No matching trig files found\n",
      "Skipping 422: No matching trig files found\n",
      "Skipping 423: No matching trig files found\n",
      "Skipping 424: No matching trig files found\n",
      "Skipping 425: No matching trig files found\n",
      "Skipping 426: No matching trig files found\n",
      "Skipping 427: No matching trig files found\n",
      "Skipping 428: No matching trig files found\n",
      "Skipping 429: No matching trig files found\n",
      "Skipping 430: No matching trig files found\n",
      "Skipping 431: No matching trig files found\n",
      "Skipping 432: No matching trig files found\n",
      "Skipping 433: No matching trig files found\n",
      "Skipping 434: No matching trig files found\n",
      "Skipping 435: No matching trig files found\n",
      "Skipping 436: No matching trig files found\n",
      "Skipping 437: No matching trig files found\n",
      "Skipping 438: No matching trig files found\n",
      "Skipping 439: No matching trig files found\n",
      "Skipping 440: No matching trig files found\n",
      "Skipping 441: No matching trig files found\n",
      "Skipping 73: No matching trig files found\n",
      "Skipping 74: No matching trig files found\n",
      "Skipping 75: No matching trig files found\n",
      "Skipping 76: No matching trig files found\n",
      "Skipping 77: No matching trig files found\n",
      "Skipping 78: No matching trig files found\n",
      "Skipping 79: No matching trig files found\n",
      "Skipping 80: No matching trig files found\n",
      "Skipping 81: No matching trig files found\n",
      "Skipping 82: No matching trig files found\n",
      "Skipping 83: No matching trig files found\n",
      "Skipping 84: No matching trig files found\n",
      "Skipping 87: No matching trig files found\n",
      "Skipping 88: No matching trig files found\n",
      "Skipping 89: No matching trig files found\n",
      "Skipping 90: No matching trig files found\n",
      "Skipping 91: No matching trig files found\n",
      "Skipping 92: No matching trig files found\n",
      "Skipping 93: No matching trig files found\n",
      "Skipping 94: No matching trig files found\n",
      "Skipping 95: No matching trig files found\n",
      "Skipping 96: No matching trig files found\n",
      "Skipping 97: No matching trig files found\n",
      "Skipping 98: No matching trig files found\n",
      "Skipping 99: No matching trig files found\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import uuid\n",
    "import anthropic\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "class EventProcessor:\n",
    "    def __init__(self, api_key: str):\n",
    "        self.client = anthropic.Anthropic(api_key=api_key)\n",
    "        self.output_dir = Path(\"rdf_output\")\n",
    "        if not self.output_dir.exists():\n",
    "            self.output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    def collect_files(self, text_id: str, trig_dir: Path) -> Tuple[str, List[Dict], List[Dict]]:\n",
    "        \"\"\"Collect text and trig files for a given text ID\"\"\"\n",
    "        text_file = Path(f\"./1891/1891/txt/{text_id}.txt\")\n",
    "        if not text_file.exists():\n",
    "            raise FileNotFoundError(f\"Text file {text_file} not found\")\n",
    "\n",
    "        with text_file.open('r', encoding='utf-8') as f:\n",
    "            text_content = f.read()\n",
    "\n",
    "        date_files = []\n",
    "        place_files = []\n",
    "\n",
    "        for trig_file in trig_dir.glob(f\"{text_id}_*.trig\"):\n",
    "            with trig_file.open('r', encoding='utf-8') as f:\n",
    "                content = f.read()\n",
    "                if 'date' in trig_file.stem.lower():\n",
    "                    date_files.append({'filename': trig_file.name, 'content': content})\n",
    "                elif 'place' in trig_file.stem.lower():\n",
    "                    place_files.append({'filename': trig_file.name, 'content': content})\n",
    "\n",
    "        return text_content, date_files, place_files\n",
    "\n",
    "    def extract_events(self, text: str, date_files: List[Dict], place_files: List[Dict]) -> Dict:\n",
    "        \"\"\"Extract events using Claude API with both text and trig files\"\"\"\n",
    "        system_prompt = \"\"\"Analyze the diary excerpt and the provided trig files to create a sequence of events representing Mary Berenson's movements in time and space. Each event should be created by matching places and dates from the text that are also represented in the trig files.\n",
    "\n",
    "For each event pair, you need to:\n",
    "1. Match places and dates that clearly belong together in the text\n",
    "2. Find the corresponding trig files for both the place and date\n",
    "3. Extract the UUIDs from the body annotations in the trig files (found in the pattern: annotation/UUID/body)\n",
    "4. Create a chronologically ordered sequence of events\n",
    "\n",
    "Return the results in this exact format, with no additional text:\n",
    "{\n",
    "    \"events\": [\n",
    "        {\n",
    "            \"event_value\": \"Fiesole, 23 September 1900\",\n",
    "            \"place_annotation_uuid\": \"uuid-from-place-trig\",\n",
    "            \"date_annotation_uuid\": \"uuid-from-date-trig\",\n",
    "            \"event_uuid\": \"new-generated-uuid\",\n",
    "            \"next_event_value\": \"Florence, 24 September 1900\",\n",
    "            \"next_event_uuid\": \"uuid-for-next-event\",\n",
    "        }\n",
    "    ]\n",
    "}\"\"\"\n",
    "\n",
    "        content = f\"\"\"Here is the diary excerpt:\n",
    "        {text}\n",
    "\n",
    "        Here are the date trig files:\n",
    "        {'-' * 50}\n",
    "        \"\"\"\n",
    "\n",
    "        for date_file in date_files:\n",
    "            content += f\"\\nFile: {date_file['filename']}\\n{date_file['content']}\\n{'-' * 50}\"\n",
    "\n",
    "        content += \"\\n\\nHere are the place trig files:\\n\" + ('-' * 50)\n",
    "\n",
    "        for place_file in place_files:\n",
    "            content += f\"\\nFile: {place_file['filename']}\\n{place_file['content']}\\n{'-' * 50}\"\n",
    "\n",
    "        try:\n",
    "            response = self.client.messages.create(\n",
    "                model=\"claude-3-sonnet-20240229\",\n",
    "                max_tokens=4096,\n",
    "                system=system_prompt,\n",
    "                temperature=0,\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": f\"Please analyze the following text and trig files to extract and match events:\\n\\n{content}\"\n",
    "                    }\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            response_text = response.content[0].text\n",
    "            json_start = response_text.find('{')\n",
    "            json_end = response_text.rfind('}') + 1\n",
    "\n",
    "            if json_start == -1 or json_end == 0:\n",
    "                raise ValueError(\"No valid JSON found in response\")\n",
    "\n",
    "            events_data = json.loads(response_text[json_start:json_end])\n",
    "            self.validate_event_uuid_sequence(events_data)\n",
    "            return events_data\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting events: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    def validate_event_uuid_sequence(self, events_data: Dict) -> None:\n",
    "        \"\"\"Validate that next_event_uuid matches the event_uuid of the next event\"\"\"\n",
    "        events = events_data.get('events', [])\n",
    "        for i in range(len(events) - 1):\n",
    "            current_event = events[i]\n",
    "            next_event = events[i + 1]\n",
    "\n",
    "            if current_event.get('next_event_uuid') != next_event.get('event_uuid'):\n",
    "                raise ValueError(\n",
    "                    f\"UUID sequence mismatch: Event {i}'s next_event_uuid \"\n",
    "                    f\"({current_event.get('next_event_uuid')}) does not match \"\n",
    "                    f\"Event {i+1}'s event_uuid ({next_event.get('event_uuid')})\"\n",
    "                )\n",
    "\n",
    "    def validate_uuids(self, events_data: Dict, date_files: List[Dict], place_files: List[Dict]) -> bool:\n",
    "        \"\"\"Validate that UUIDs in events match those in trig files\"\"\"\n",
    "        for event in events_data.get('events', []):\n",
    "            place_uuid = event.get('place_annotation_uuid')\n",
    "            date_uuid = event.get('date_annotation_uuid')\n",
    "\n",
    "            place_found = any(place_uuid in place_file['content'] for place_file in place_files)\n",
    "            date_found = any(date_uuid in date_file['content'] for date_file in date_files)\n",
    "\n",
    "            if not (place_found and date_found):\n",
    "                print(f\"UUID validation failed for event: {event['event_value']}\")\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    def convert_to_trig(self, event_data: Dict) -> str:\n",
    "        \"\"\"Convert a single event data to Trig format\"\"\"\n",
    "        trig_template = f\"\"\"\n",
    "        <https://mbdiaries.itatti.harvard.edu/annotation/{event_data.get('event_uuid', '')}/body>\n",
    "            a crm:E5_event;\n",
    "            crm:P160_has_temporal_projection <https://mbdiaries.itatti.harvard.edu/annotation/{event_data.get('date_annotation_uuid', '')}//body>;\n",
    "            crm:P161_has_spatial_projection <https://mbdiaries.itatti.harvard.edu/annotation/{event_data.get('place_annotation_uuid', '')}/body>;\n",
    "            crm:P183_ends_before_the_start <https://mbdiaries.itatti.harvard.edu/annotation/{event_data.get('next_event_uuid', '')}/body>\n",
    "        \"\"\"\n",
    "        return trig_template\n",
    "\n",
    "    def save_events_as_trig(self, events_data: Dict, text_id: str):\n",
    "        \"\"\"Save events to individual Trig files\"\"\"\n",
    "        if not events_data or 'events' not in events_data:\n",
    "            print(\"No events to save\")\n",
    "            return\n",
    "\n",
    "        for i, event in enumerate(events_data['events'], 1):\n",
    "            trig_content = self.convert_to_trig(event)\n",
    "            trig_filename = self.output_dir / f\"{text_id}_event_{event['event_uuid']}.trig\"\n",
    "\n",
    "            try:\n",
    "                with trig_filename.open('w', encoding='utf-8') as f:\n",
    "                    f.write(trig_content)\n",
    "                print(f\"Saved Trig file: {trig_filename}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error saving Trig file for event {i}: {str(e)}\")\n",
    "\n",
    "def main():\n",
    "    api_key = \"\"\n",
    "    input_dir = Path(\"./1891/1891/txt\")\n",
    "    trig_dir = Path(\"rdf_output\")\n",
    "    output_dir = Path(\"output\")\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    try:\n",
    "        processor = EventProcessor(api_key)\n",
    "\n",
    "        # Get sorted list of all text files\n",
    "        text_files = sorted(list(input_dir.glob('*.txt')))\n",
    "        \n",
    "        # Process each text file\n",
    "        for i, text_file in enumerate(text_files):\n",
    "            text_id = text_file.stem\n",
    "            \n",
    "            # Collect date and place trig files for current text\n",
    "            date_files, place_files = [], []\n",
    "            for trig_file in trig_dir.glob(f\"{text_id}_*.trig\"):\n",
    "                with trig_file.open('r', encoding='utf-8') as f:\n",
    "                    content = f.read()\n",
    "                    if 'date' in trig_file.stem.lower():\n",
    "                        date_files.append({'filename': trig_file.name, 'content': content})\n",
    "                    elif 'place' in trig_file.stem.lower():\n",
    "                        place_files.append({'filename': trig_file.name, 'content': content})\n",
    "\n",
    "            if not date_files or not place_files:\n",
    "                print(f\"Skipping {text_id}: No matching trig files found\")\n",
    "                continue\n",
    "\n",
    "            # Process current text\n",
    "            text_content = text_file.read_text(encoding='utf-8')\n",
    "            current_events_data = processor.extract_events(text_content, date_files, place_files)\n",
    "            \n",
    "            if not current_events_data or 'events' not in current_events_data:\n",
    "                continue\n",
    "\n",
    "            # Look for the first event in the next 3 texts\n",
    "            next_event = None\n",
    "            for j in range(i + 1, min(i + 4, len(text_files))):\n",
    "                next_text_file = text_files[j]\n",
    "                next_text_id = next_text_file.stem\n",
    "                \n",
    "                # Collect trig files for next text\n",
    "                next_date_files, next_place_files = [], []\n",
    "                for trig_file in trig_dir.glob(f\"{next_text_id}_*.trig\"):\n",
    "                    with trig_file.open('r', encoding='utf-8') as f:\n",
    "                        content = f.read()\n",
    "                        if 'date' in trig_file.stem.lower():\n",
    "                            next_date_files.append({'filename': trig_file.name, 'content': content})\n",
    "                        elif 'place' in trig_file.stem.lower():\n",
    "                            next_place_files.append({'filename': trig_file.name, 'content': content})\n",
    "\n",
    "                if next_date_files and next_place_files:\n",
    "                    next_text_content = next_text_file.read_text(encoding='utf-8')\n",
    "                    next_events_data = processor.extract_events(next_text_content, next_date_files, next_place_files)\n",
    "                    \n",
    "                    if next_events_data and 'events' in next_events_data and next_events_data['events']:\n",
    "                        next_event = next_events_data['events'][0]\n",
    "                        break\n",
    "\n",
    "            # Update the last event in current text with next event information\n",
    "            if next_event and current_events_data['events']:\n",
    "                last_event = current_events_data['events'][-1]\n",
    "                last_event['next_event_value'] = next_event['event_value']\n",
    "                last_event['next_event_uuid'] = next_event['event_uuid']\n",
    "\n",
    "            # Save processed events\n",
    "            output_json_path = output_dir / f\"{text_id}_events.json\"\n",
    "            with output_json_path.open('w', encoding='utf-8') as f:\n",
    "                json.dump(current_events_data, f, indent=2)\n",
    "\n",
    "            # Save events as Trig files\n",
    "            processor.save_events_as_trig(current_events_data, text_id)\n",
    "\n",
    "            print(f\"\\nProcessed {text_id}:\")\n",
    "            for event in current_events_data['events']:\n",
    "                print(f\"\\nEvent: {event['event_value']}\")\n",
    "                print(f\"Place UUID: {event['place_annotation_uuid']}\")\n",
    "                print(f\"Date UUID: {event['date_annotation_uuid']}\")\n",
    "                print(f\"Event UUID: {event['event_uuid']}\")\n",
    "                if 'next_event_value' in event:\n",
    "                    print(f\"Next Event: {event['next_event_value']}\")\n",
    "                    print(f\"Next Event UUID: {event['next_event_uuid']}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in main execution: {str(e)}\")\n",
    "        print(\"Please ensure:\")\n",
    "        print(\"1. The 'input' directory exists\")\n",
    "        print(\"2. Text and trig files are in the input directory\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "snV7S--ncPDp"
   },
   "source": [
    "a questo punto userei un approccio di questo tipo:\n",
    "al momento di estrazione dei JSON aggiungerei un campo di UUID in cui estraggo il main\n",
    "successivamente formatto in trig\n",
    "\n",
    "poi chiedo all llm di vedere di nuovo il testo ed estrarre combinazioni di luogo e tempo da dover poi definire come \"event\" in CIDOC crm. In questo file devo poi anche indicare l'UUID dell'evento successivo come next event e gli UUID del luogo e tempo in cui succede\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
